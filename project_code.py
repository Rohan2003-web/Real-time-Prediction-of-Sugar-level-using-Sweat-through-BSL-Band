# -*- coding: utf-8 -*-
"""Project Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kztW-MIObm_-MsqoVxJ91mHtMk58DwVM

Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

sns.set()

from mlxtend.plotting import plot_decision_regions
import missingno as msno
from pandas.plotting import scatter_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

"""Reading the dataset"""

from google.colab import drive
drive.mount('/content/drive')

path='/content/drive/My Drive/Colab Notebooks/SugarDataset1.xlsx'
my_data = pd.read_excel(path)
my_data

"""Columns available in our dataset."""

my_data.columns

"""Information about the dataset"""

my_data.info()

my_data.describe()

my_data.describe().T

my_data.isnull().head(10)

my_data.isnull().sum()

my_data_copy = my_data.copy(deep = True)
my_data_copy[['Glucose','BloodPressure','Age','BMI']] = my_data_copy[['Glucose','BloodPressure','Age','BMI']].replace(0,np.NaN)

print(my_data_copy.isnull().sum())

"""Data Visualization :
Plotting the data distribution plots before removing null values
"""

p = my_data.hist(figsize = (10,10))

"""Scaling the Data"""

my_data_copy.head()

"""Model Building :
Splitting the dataset
"""

sc_X = StandardScaler()
X =  pd.DataFrame(sc_X.fit_transform(my_data_copy.drop(["Outcome"],axis = 1),), columns=['Glucose','BloodPressure', 'Age', 'BMI'])
X.head()

"""Model Building :
Splitting the dataset
"""

X = my_data.drop('Outcome', axis=1)
y = my_data['Outcome']

"""split the data into training and testing data using the train_test_split function"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33,
                                                    random_state=7)

"""Random Forest :
Building the model using RandomForest
"""

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=200)
rfc.fit(X_train, y_train)

"""Check the accuracy of the model on the training dataset."""

rfc_train = rfc.predict(X_train)
from sklearn import metrics

print("Accuracy_Score =", format(metrics.accuracy_score(y_train, rfc_train)))

"""Getting the accuracy score for Random Forest"""

from sklearn import metrics

predictions = rfc.predict(X_test)
print("Accuracy_Score =", format(metrics.accuracy_score(y_test, predictions)))

"""Classification report and confusion matrix of random forest model"""

# Make predictions on the test data
y_pred = rfc.predict(X_test)

# Generate a confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Generate a classification report
class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

"""Decision Tree :
Building the model using DecisionTree


"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)

"""Getting the accuracy score for Decision Tree"""

from sklearn import metrics

predictions = dtree.predict(X_test)
print("Accuracy Score =", format(metrics.accuracy_score(y_test,predictions)))

"""Classification report and confusion matrix of the decision tree model"""

from sklearn.metrics import classification_report, confusion_matrix

print("Confusion Matrix:")
print(confusion_matrix(y_test, predictions))

print("\nClassification Report:")
print(classification_report(y_test,predictions))

"""Support Vector Machine (SVM) :
Building the model using Support Vector Machine (SVM)
"""

from sklearn.svm import SVC

svc_model = SVC()
svc_model.fit(X_train, y_train)

"""Prediction from support vector machine model on the testing data"""

svc_pred = svc_model.predict(X_test)

"""Accuracy score for SVM"""

from sklearn import metrics

print("Accuracy Score =", format(metrics.accuracy_score(y_test, svc_pred)))

"""Classification report and confusion matrix of the SVM classifier"""

from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test, svc_pred))
print(classification_report(y_test,svc_pred))

"""Feature Importance : Getting feature importances"""

rfc.feature_importances_

"""Plotting feature importances"""

(pd.Series(rfc.feature_importances_, index=X.columns).plot(kind='barh'))

"""Saving Model â€“ Random Forest"""

import pickle

# Firstly we will be using the dump() function to save the model using pickle
saved_model = pickle.dumps(rfc)

# Then we will be loading that saved model
rfc_from_pickle = pickle.loads(saved_model)

# lastly, after loading that model we will use this to make predictions
rfc_from_pickle.predict(X_test)

my_data.head()

my_data.tail()

"""Putting data points in the model will either return 0 or 1 i.e. person suffering from diabetes or not."""

rfc.predict([[137,40,33,28.1]])    #4th patient

svc_model.predict([[95,110,52,30.1]]) #767th patient